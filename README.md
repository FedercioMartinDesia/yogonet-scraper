üì∞ Yogonet Scraper ‚Äì IA + Python + BigQuery + Railway

Este proyecto automatiza el scraping de noticias de Yogonet utilizando un enfoque inteligente basado en IA (OpenAI GPT-4o) para identificar din√°micamente los campos clave de cada nota (T√≠tulo, Kicker, Imagen, Link), procesa la informaci√≥n y la carga en una tabla de Google BigQuery.

Deploy de referencia: Se realiza en Railway para evitar problemas con la facturaci√≥n de Google Cloud Platform.
Arquitectura desacoplada: todo corre en Docker, puede adaptarse a Cloud Run f√°cilmente.

üìÇ Estructura del proyecto

yogonet-scraper/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Punto de entrada, orquesta todo
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py           # Scraping IA-driven con OpenAI
‚îÇ   ‚îú‚îÄ‚îÄ processor.py         # Procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ bq_loader.py         # Inserci√≥n en BigQuery
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt         # Dependencias Python
‚îú‚îÄ‚îÄ Dockerfile               # Imagen Docker para Railway/Cloud Run
‚îú‚îÄ‚îÄ README.md                # (Este archivo)


üöÄ C√≥mo ejecutar el scraper

1. Prerrequisitos
Cuenta de Google Cloud con un proyecto y una tabla BigQuery ya creada.

Credenciales de Service Account descargadas en JSON.

Una API key de OpenAI.

Una cuenta en Railway (gratis, sin tarjeta) para desplegar.

2. Configuraci√≥n de variables

Vas a necesitar 2 variables de entorno (se cargan en Railway > Variables):

GCP_CREDS_JSON: Contenido completo del archivo JSON de credenciales (Service Account de GCP).

OPENAI_API_KEY: Tu API Key de OpenAI (GPT-4o).

3. Deploy autom√°tico en Railway
   
Sub√≠ este repositorio a GitHub
(Si ya est√°, salte√° este paso).

En Railway:

Click en New Project > Deploy from GitHub Repo

Eleg√≠ tu repo.

Railway detecta el Dockerfile y hace build autom√°tico.

Agreg√° variables de entorno:

En Settings > Variables:

Peg√° el contenido de tu JSON de credenciales en GCP_CREDS_JSON

Peg√° tu clave de OpenAI en OPENAI_API_KEY

Railway hace deploy autom√°tico.

El script corre y carga los datos en BigQuery.

Ver logs en el dashboard (opci√≥n ‚ÄúView logs‚Äù).

4. ¬øC√≥mo correrlo localmente?

Instal√° dependencias:
pip install -r requirements.txt

Export√° las variables de entorno en tu terminal:

export GCP_CREDS_JSON="$(cat /ruta/a/credenciales.json)"
export OPENAI_API_KEY="sk-...."

Corr√© el script principal:

python app/main.py

5. ¬øC√≥mo funcionar√≠a en Cloud Run?

Este mismo Dockerfile y c√≥digo es 100% compatible con Cloud Run.

Simplemente sub√≠ tu imagen a Google Artifact Registry o Docker Hub y despleg√° en Cloud Run.

En Cloud Run, configur√° las variables de entorno GCP_CREDS_JSON y OPENAI_API_KEY igual que en Railway.



