<img width="829" height="228" alt="image" src="https://github.com/user-attachments/assets/e0c21a9d-1853-4ebe-b454-7a890dc4ef21" /># ğŸ“° Yogonet Scraper â€“ IA + Python + BigQuery + Railway

Este proyecto automatiza el scraping de noticias de Yogonet utilizando un enfoque inteligente basado en IA (OpenAI GPT-4o) para identificar dinÃ¡micamente los campos clave de cada nota (**TÃ­tulo, Kicker, Imagen, Link**), procesa la informaciÃ³n y la carga en una tabla de Google BigQuery.

- **Deploy de referencia:** Railway (evita problemas de facturaciÃ³n de GCP)
- **Arquitectura desacoplada:** todo corre en Docker, se puede adaptar a Cloud Run.

---

## ğŸ“‚ Estructura del proyecto

```plaintext
yogonet-scraper/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Punto de entrada, orquesta todo
â”‚   â”œâ”€â”€ scraper.py           # Scraping IA-driven con OpenAI
â”‚   â”œâ”€â”€ processor.py         # Procesamiento de datos
â”‚   â”œâ”€â”€ bq_loader.py         # InserciÃ³n en BigQuery
â”‚
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”œâ”€â”€ Dockerfile               # Imagen Docker para Railway/Cloud Run
â”œâ”€â”€ README.md                # (Este archivo)
```
---

### ğŸš€ CÃ³mo ejecutar el scraper

#### 1. Prerrequisitos

Para poner en marcha este proyecto, necesitarÃ¡s lo siguiente:

* Una cuenta de Google Cloud con un proyecto y una tabla de BigQuery ya creada.
* Credenciales de Service Account de Google Cloud en formato JSON.
* Una API Key de OpenAI (GPT-4o).
* Una cuenta en Railway (es gratis, no requiere tarjeta de crÃ©dito).

#### 2. ConfiguraciÃ³n de variables de entorno

Debes configurar dos variables de entorno para que el proyecto funcione:

* **`GCP_CREDS_JSON`**: El contenido completo de tu archivo JSON de credenciales de Google Cloud (Service Account).
* **`OPENAI_API_KEY`**: Tu API Key de OpenAI.

Estas variables se cargan en la configuraciÃ³n de Railway.

<img width="829" height="228" alt="image" src="https://github.com/user-attachments/assets/cc8041c9-7ae4-440c-b2ae-a582f3c375ea" />
<img width="824" height="234" alt="image" src="https://github.com/user-attachments/assets/64176f47-c706-4bb5-a1d9-592014520749" />
<img width="799" height="213" alt="image" src="https://github.com/user-attachments/assets/661b1e16-e173-4634-8d12-9eab70ba6bd2" />
<img width="466" height="59" alt="image" src="https://github.com/user-attachments/assets/5d4cf209-91e2-494c-96dd-c5843e8ee552" />


#### 3. Despliegue automÃ¡tico en Railway

1.  Sube este repositorio a **GitHub**.
2.  En Railway, haz clic en **New Project** y luego en **Deploy from GitHub Repo**.
3.  Selecciona tu repositorio. Railway detectarÃ¡ el **Dockerfile** y harÃ¡ el _build_ de forma automÃ¡tica.
4.  Configura las variables de entorno en **Settings > Variables**. Pega el contenido de tu JSON en `GCP_CREDS_JSON` y tu clave de OpenAI en `OPENAI_API_KEY`.
5.  Railway harÃ¡ el _deploy_ automÃ¡ticamente. El _script_ se ejecutarÃ¡ y cargarÃ¡ los datos en BigQuery. Puedes verificar el progreso y los resultados en la opciÃ³n **View logs** del _dashboard_.

#### 4. EjecuciÃ³n local

Si prefieres ejecutar el _scraper_ en tu mÃ¡quina local, sigue estos pasos:

1.  Instala las dependencias de Python:
    ```bash
    pip install -r requirements.txt
    ```
2.  Exporta las variables de entorno en tu terminal:
    ```bash
    export GCP_CREDS_JSON="$(cat /ruta/a/credenciales.json)"
    export OPENAI_API_KEY="sk-...."
    ```
3.  Corre el _script_ principal:
    ```bash
    python app/main.py
    ```

#### 5. Despliegue en Cloud Run

Este proyecto es 100% compatible con Google Cloud Run. Simplemente sube la imagen Docker a Google Artifact Registry o Docker Hub y despliÃ©gala en Cloud Run. DeberÃ¡s configurar las variables de entorno `GCP_CREDS_JSON` y `OPENAI_API_KEY` en el servicio de Cloud Run, de la misma manera que lo harÃ­as en Railway.

```plaintext
#!/bin/bash
docker build -t gcr.io/tu-proyecto/tu-imagen .
docker push gcr.io/tu-proyecto/tu-imagen
gcloud run deploy tu-servicio --image gcr.io/tu-proyecto/tu-imagen --platform managed --region us-central1
```




---
### Â¿CÃ³mo cambiar la URL de la noticia a scrapear?

Por defecto, la URL de la noticia a scrapear estÃ¡ definida en app/main.py en la variable news_url.
Puedes editar ese valor antes de correr el script para probar diferentes noticias de Yogonet.

Si deseas hacer el scraper interactivo, reemplaza la lÃ­nea:
```
news_url = "https://www.yogonet.com/international/news/....."

```

---

### âš™ï¸ Dependencias clave

El proyecto se basa en las siguientes librerÃ­as de Python:

* `requests` y `beautifulsoup4`: Para la descarga y el parseo de HTML.
* `openai`: Para la selecciÃ³n dinÃ¡mica de campos con GPT-4o.
* `pandas`, `pyarrow`, `pandas-gbq`: Para el procesamiento de datos y la carga en BigQuery.
* `google-cloud-bigquery`: Para la conexiÃ³n y la gestiÃ³n de BigQuery.




